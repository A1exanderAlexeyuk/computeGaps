---
title: "Prevalence Analysis Guide"
author: "computeGaps Package"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prevalence Analysis Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

# Introduction

The `computeGaps` package provides a comprehensive solution for analyzing treatment gaps and test utilization patterns in OMOP Common Data Model (CDM) cohorts. This guide walks through the complete workflow from data preparation to result analysis.

## Key Features

- **Database-Efficient Analysis**: All computations performed using SQL queries
- **TSV Configuration**: Flexible input format with JSON metadata
- **OMOP CDM Compatible**: Works with standard OMOP domains
- **Time Window Analysis**: Configurable time periods around index dates
- **Tibble Output**: Results returned as tibbles for easy analysis

# Installation and Setup

```{r installation}
# Install from GitHub
# devtools::install_github("A1exanderAlexeyuk/computeGaps")

# Load the package
library(computeGaps)
library(DatabaseConnector)
library(dplyr)
library(tidyr)
```

# Database Connection

```{r connection}
# SQL Server example using DatabaseConnector with JDBC
connection <- DatabaseConnector::connect(
  dbms = "sql server",
  server = "your_server_name",
  user = "your_username",
  password = "your_password",
  pathToDriver = "path/to/jdbc/drivers"
)

# PostgreSQL example using DatabaseConnector with JDBC
connection <- DatabaseConnector::connect(
  dbms = "postgresql",
  server = "your_server/your_database",
  user = "your_username", 
  password = "your_password",
  pathToDriver = "path/to/jdbc/drivers"
)

# Oracle example using DatabaseConnector
connection <- DatabaseConnector::connect(
  dbms = "oracle",
  server = "your_server/your_service_name",
  user = "your_username",
  password = "your_password",
  pathToDriver = "path/to/jdbc/drivers"
)

# BigQuery example using DatabaseConnector
connection <- DatabaseConnector::connect(
  dbms = "bigquery",
  connectionString = "jdbc:bigquery://https://www.googleapis.com/bigquery/v2:443;ProjectId=your_project_id;OAuthType=0;OAuthServiceAcctEmail=your_service_account@project.iam.gserviceaccount.com;OAuthPvtKeyPath=path/to/key.json;",
  pathToDriver = "path/to/jdbc/drivers"
)

# Redshift example using DatabaseConnector
connection <- DatabaseConnector::connect(
  dbms = "redshift",
  server = "your_cluster.region.redshift.amazonaws.com/your_database",
  user = "your_username",
  password = "your_password",
  pathToDriver = "path/to/jdbc/drivers",
  port = 5439
)

# Using connection details object for reusability
connectionDetails <- DatabaseConnector::createConnectionDetails(
  dbms = "postgresql",
  server = "your_server/your_database",
  user = "your_username",
  password = "your_password",
  pathToDriver = "path/to/jdbc/drivers"
)

connection <- DatabaseConnector::connect(connectionDetails)

# Download JDBC drivers if needed
DatabaseConnector::downloadJdbcDrivers(dbms = "postgresql", pathToDriver = "path/to/jdbc/drivers")
DatabaseConnector::downloadJdbcDrivers(dbms = "sql server", pathToDriver = "path/to/jdbc/drivers")
DatabaseConnector::downloadJdbcDrivers(dbms = "oracle", pathToDriver = "path/to/jdbc/drivers")
DatabaseConnector::downloadJdbcDrivers(dbms = "redshift", pathToDriver = "path/to/jdbc/drivers")
```

# Input Data Format

The package expects TSV files with specific columns and JSON metadata:

## Required Columns

| Column | Type | Description |
|--------|------|-------------|
| `cohortname` | Character | Cohort identifier |
| `concept_id_1` | Numeric | Cohort concept ID |
| `concept_id_2` | Numeric | Test/procedure concept ID |
| `omop_object_domain` | Character | OMOP domain |
| `object_custom_name` | Character | Test/procedure name |
| `predicate_metadata` | Character | JSON with time windows |

## JSON Metadata Format

```json
{
  "Workflow stage": "Confirmatory Diagnosis",
  "time_gap_in_days": 7,
  "days_around_index_1": -14,
  "days_around_index_2": 0
}
```

- `days_around_index_1`: Start of time window (negative = before index date)
- `days_around_index_2`: End of time window (positive = after index date)

# Creating Sample Data

```{r sample_data}
# Create sample TSV file
sample_file <- create_sample_tsv("sample_analysis.tsv", n_rows = 5)

# Validate the structure
tsv_data <- read_and_validate_tsv("sample_analysis.tsv")
validation_result <- validate_tsv_structure(tsv_data, verbose = TRUE)
```

# Running Prevalence Analysis

## Basic Analysis

```{r basic_analysis}
# Run prevalence analysis and get results as a tibble
results <- compute_prevalence_from_tsv(
  tsv_file_path = "sample_analysis.tsv",
  connection = connection,
  cdm_database_schema = "cdm_schema",
  cohort_database_schema = "cohort_schema",
  cohort_table_name = "cohort"
)

# View the results
print(results)

# Check column names
names(results)
```

## Working with Results

```{r working_with_results}
# Filter high prevalence results
high_prevalence <- results %>%
  filter(patient_count >= 10.0)

# Group by cohort
cohort_summary <- results %>%
  group_by(cohortname) %>%
  summarise(
    total_tests = n(),
    avg_prevalence = mean(patient_count, na.rm = TRUE),
    max_prevalence = max(patient_count, na.rm = TRUE)
  )

# Group by workflow stage
workflow_summary <- results %>%
  group_by(workflow_stage) %>%
  summarise(
    total_tests = n(),
    avg_prevalence = mean(patient_count, na.rm = TRUE),
    patients_tested = sum(n_patients_with_op, na.rm = TRUE)
  )

# Filter by domain
procedure_results <- results %>%
  filter(omop_object_domain == "Procedure")

# Sort by prevalence
top_tests <- results %>%
  arrange(desc(patient_count)) %>%
  head(20)
```

## Advanced Analysis

```{r advanced_analysis}
# Analyze prevalence patterns across time windows
time_window_analysis <- results %>%
  mutate(
    window_start = days_around_index_1,
    window_end = days_around_index_2,
    window_size = window_end - window_start
  ) %>%
  group_by(window_size, workflow_stage) %>%
  summarise(
    avg_prevalence = mean(patient_count, na.rm = TRUE),
    n_tests = n()
  )

# Compare prevalence across cohorts
cohort_comparison <- results %>%
  select(cohortname, object_custom_name, patient_count) %>%
  pivot_wider(
    names_from = cohortname,
    values_from = patient_count,
    values_fill = 0
  )

# Find tests with high variability across cohorts
variability_analysis <- results %>%
  group_by(object_custom_name) %>%
  summarise(
    n_cohorts = n_distinct(cohortname),
    prevalence_sd = sd(patient_count, na.rm = TRUE),
    prevalence_range = max(patient_count, na.rm = TRUE) - min(patient_count, na.rm = TRUE)
  ) %>%
  filter(n_cohorts > 1) %>%
  arrange(desc(prevalence_sd))
```

# Exporting Results

## File Exports

```{r exports}
# Export to CSV
write.csv(results, "prevalence_results.csv", row.names = FALSE)

# Export to TSV
write.table(results, "prevalence_results.tsv", sep = "\t", row.names = FALSE)

# Export to Excel (requires writexl package)
# writexl::write_xlsx(results, "prevalence_results.xlsx")

# Export filtered results
high_prevalence_results <- results %>%
  filter(patient_count >= 10.0)
write.csv(high_prevalence_results, "high_prevalence_results.csv", row.names = FALSE)

# Export summary statistics
summary_stats <- results %>%
  group_by(cohortname, workflow_stage) %>%
  summarise(
    n_tests = n(),
    avg_prevalence = mean(patient_count, na.rm = TRUE),
    total_patients_tested = sum(n_patients_with_op, na.rm = TRUE)
  )
write.csv(summary_stats, "prevalence_summary.csv", row.names = FALSE)
```

# Understanding Results

## Output Structure

The results tibble contains:

| Column | Description |
|--------|-------------|
| `cohortname` | Cohort identifier |
| `omop_object_domain` | OMOP domain |
| `object_custom_name` | Test/procedure name |
| `workflow_stage` | Workflow stage |
| `n_patients` | Total patients in cohort |
| `n_patients_with_op` | Patients with test/procedure |
| `patient_count` | **Prevalence percentage** |
| `days_around_index_1` | Start of time window |
| `days_around_index_2` | End of time window |

## Interpreting Prevalence

- `patient_count` represents the percentage of patients in the cohort who had the specific test/procedure within the defined time window
- `n_patients` is the total cohort size
- `n_patients_with_op` is the count of patients who had the test/procedure

Example: If `patient_count = 25.5`, this means 25.5% of patients in the cohort had this test/procedure.

# Advanced Features

## Custom Time Windows

Modify the `predicate_metadata` in your TSV file:

```json
{
  "Workflow stage": "Extended Follow-up",
  "days_around_index_1": -90,
  "days_around_index_2": 180
}
```

This analyzes tests from 90 days before to 180 days after the index date.

## Multiple Workflow Stages

The same test can be analyzed across different stages by including multiple rows with different metadata:

```
cohortname	concept_id_1	concept_id_2	...	predicate_metadata
IBD Cohort	81893	606840	...	{"Workflow stage": "Initial", "days_around_index_1": -30, "days_around_index_2": 0}
IBD Cohort	81893	606840	...	{"Workflow stage": "Follow-up", "days_around_index_1": 30, "days_around_index_2": 90}
```

# Supported OMOP Domains

The package supports these OMOP domains:

- **Procedure** (`procedure_occurrence`)
- **Measurement** (`measurement`) 
- **Condition** (`condition_occurrence`)
- **Drug** (`drug_exposure`)
- **Device** (`device_exposure`)
- **Observation** (`observation`)

# Visualization Examples

```{r visualization}
# Create visualizations with ggplot2
library(ggplot2)

# Prevalence by workflow stage
ggplot(results, aes(x = workflow_stage, y = patient_count)) +
  geom_boxplot() +
  theme_minimal() +
  labs(
    title = "Prevalence Distribution by Workflow Stage",
    x = "Workflow Stage",
    y = "Prevalence (%)"
  )

# Top 10 most prevalent tests
top_10 <- results %>%
  arrange(desc(patient_count)) %>%
  head(10)

ggplot(top_10, aes(x = reorder(object_custom_name, patient_count), y = patient_count)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(
    title = "Top 10 Most Prevalent Tests/Procedures",
    x = "",
    y = "Prevalence (%)"
  )

# Prevalence heatmap by cohort and test
library(tidyr)
heatmap_data <- results %>%
  select(cohortname, object_custom_name, patient_count) %>%
  pivot_wider(names_from = cohortname, values_from = patient_count, values_fill = 0)

# Convert to matrix for heatmap (if needed)
# heatmap_matrix <- as.matrix(heatmap_data[,-1])
# rownames(heatmap_matrix) <- heatmap_data$object_custom_name
```

# Testing and Validation

## Data Validation

```{r validation}
# Validate TSV structure before analysis
tsv_data <- read_and_validate_tsv("your_data.tsv")
validation_result <- validate_tsv_structure(tsv_data, verbose = TRUE)

if (!validation_result) {
  stop("Please fix validation errors before proceeding")
}

# Check for missing values in results
missing_summary <- results %>%
  summarise_all(~sum(is.na(.)))
print(missing_summary)

# Validate prevalence values
invalid_prevalence <- results %>%
  filter(patient_count < 0 | patient_count > 100)

if (nrow(invalid_prevalence) > 0) {
  warning("Found invalid prevalence values")
  print(invalid_prevalence)
}
```

# Best Practices

## Performance Optimization

1. **Use appropriate time windows**: Avoid overly broad time ranges
2. **Index your cohort table**: Ensure proper indexing on `subject_id` and `cohort_start_date`
3. **Batch processing**: Process large TSV files in chunks if needed
4. **Database resources**: Monitor database performance during large analyses

## Data Quality

1. **Validate input data**: Always run `validate_tsv_structure()` first
2. **Check concept IDs**: Ensure concept IDs exist in your CDM
3. **Review time windows**: Verify `days_around_index_1` and `days_around_index_2` make sense
4. **Monitor results**: Check for unexpected prevalence patterns

## Result Interpretation

1. **Consider cohort size**: Small cohorts may have unstable prevalence estimates
2. **Account for time windows**: Different time windows will yield different prevalences
3. **Domain-specific considerations**: Different domains have different data completeness patterns
4. **Clinical context**: Interpret results within appropriate clinical context

# Troubleshooting

## Common Issues

### Database Connection Problems
- Verify connection parameters
- Check database permissions
- Ensure required schemas exist
- Verify JDBC drivers are properly installed
- Check `pathToDriver` points to correct location

### TSV Validation Errors
- Check column names match exactly
- Verify JSON metadata format
- Ensure no missing required values

### No Results Found
- Verify cohort table exists and has data
- Check concept IDs exist in CDM
- Confirm time windows are appropriate
- Review domain table availability

### Performance Issues
- Consider smaller time windows
- Check database indexes
- Monitor database resources
- Process TSV file in smaller batches

# Conclusion

The `computeGaps` package provides a robust solution for prevalence analysis in OMOP CDM environments. By following this guide, you can effectively analyze treatment gaps and test utilization patterns across different cohorts and time periods, with results returned as easy-to-analyze tibbles.

For additional support:
- Check the package documentation
- Review example scripts in `inst/examples/`
- Create issues on GitHub
- Consult the OHDSI community

```{r cleanup}
# Always disconnect when finished
DatabaseConnector::disconnect(connection)
```